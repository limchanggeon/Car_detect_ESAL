"""
Background worker thread for video stream processing and inference
"""

import time
import math
from PyQt5 import QtCore, QtGui
from typing import Optional, Tuple, Dict
from ..core.detector import VehicleDetector, VehicleTracker
from ..database import TrafficDatabaseManager

class StreamWorker(QtCore.QThread):
    """
    ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì½ê³  ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ì—¬ QImageë¥¼ ë°©ì¶œí•˜ëŠ” ì›Œì»¤ ìŠ¤ë ˆë“œ
    
    roi ì†ì„±ì´ ì„¤ì •ë˜ë©´ í•´ë‹¹ ì˜ì—­ë§Œ í¬ë¡­í•´ì„œ ì¶”ë¡ í•˜ê³ , 
    ê²°ê³¼ë¥¼ ì›ë³¸ í”„ë ˆì„ì— ì˜¤ë²„ë ˆì´í•œë‹¤.
    """

    frame_ready = QtCore.pyqtSignal(object)  # QImage
    status = QtCore.pyqtSignal(str)
    count_changed = QtCore.pyqtSignal(object)  # Dict[str, int]

    def __init__(self, source: str, detector: VehicleDetector, performance_config: dict = None, 
                 db_manager: TrafficDatabaseManager = None, camera_id: str = None):
        super().__init__()
        self.source = source
        self.detector = detector
        self._running = True
        
        # ì„±ëŠ¥ ì„¤ì • (ê¸°ë³¸ê°’ ì‚¬ìš© ë˜ëŠ” ì „ë‹¬ë°›ì€ ì„¤ì •)
        self.performance_config = performance_config or {
            "sleep_time": 0.1,
            "imgsz": 640
        }
        
        # ROI: (x, y, w, h) in ì›ë³¸ í”„ë ˆì„ í”½ì…€ ì¢Œí‘œ ë˜ëŠ” None
        self.roi = None
        
        # ì°¨ëŸ‰ ì¶”ì ê¸°
        self.tracker = VehicleTracker()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
        self.db_manager = db_manager
        self.camera_id = camera_id or f"cam_{int(time.time())}"
        self.detection_buffer = []  # íƒì§€ ê²°ê³¼ ë²„í¼
        self.last_db_save = time.time()
        
        # FPS ì¸¡ì •ìš© ë³€ìˆ˜ë“¤
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0.0

    def stop(self):
        """ì›Œì»¤ ìŠ¤ë ˆë“œ ì¤‘ì§€"""
        self._running = False

    def run(self):
        """ë©”ì¸ ì›Œì»¤ ë£¨í”„"""
        import cv2
        
        # ì†ŒìŠ¤ ì—´ê¸° ì‹œë„
        cap = cv2.VideoCapture(self.source)
        
        if not cap.isOpened():
            self.status.emit("ì†ŒìŠ¤ ì—´ê¸° ì‹¤íŒ¨")
            return

        self.status.emit("ì‹¤í–‰ ì¤‘")
        frame_count = 0
        last_fps_update = time.time()
        
        while self._running:
            ret, frame = cap.read()
            if not ret:
                # ë¹„ë””ì˜¤ íŒŒì¼ì˜ ëì— ë„ë‹¬í–ˆì„ ë•Œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue

            frame_count += 1
            
            # í”„ë ˆì„ ì²˜ë¦¬ ë° íƒì§€ ìˆ˜í–‰
            annotated_frame = self._process_frame(frame)
            
            # QImageë¡œ ë³€í™˜í•˜ì—¬ ë°©ì¶œ
            qimg = self._frame_to_qimage(annotated_frame)
            if qimg is not None:
                self.frame_ready.emit(qimg)
            
            # FPS ê³„ì‚°
            current_time = time.time()
            self.fps_counter += 1
            
            # 1ì´ˆë§ˆë‹¤ FPS ì—…ë°ì´íŠ¸
            if current_time - last_fps_update >= 1.0:
                self.current_fps = self.fps_counter / (current_time - last_fps_update)
                self.fps_counter = 0
                last_fps_update = current_time
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸ (ëœ ìì£¼ ì—…ë°ì´íŠ¸í•˜ì—¬ UI ë¶€í•˜ ê°ì†Œ)
            if frame_count % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ ì—…ë°ì´íŠ¸
                total_count = self.tracker.count
                self.status.emit(f"ğŸ¥ FPS: {self.current_fps:.1f} | í”„ë ˆì„: {frame_count} | ì¹´ìš´íŠ¸: {total_count}")
            
            # ì ì ˆí•œ í”„ë ˆì„ë ˆì´íŠ¸ ìœ ì§€ (ë¶€ë“œëŸ¬ìš´ ì¬ìƒì„ ìœ„í•´ sleep ì‹œê°„ ë‹¨ì¶•)
            sleep_time = self.performance_config.get("sleep_time", 0.03)  # 33FPS ëª©í‘œ
            time.sleep(sleep_time)

        cap.release()
        self.status.emit("ì¤‘ì§€ë¨")

    def _process_frame(self, frame) -> any:
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ì°¨ëŸ‰ íƒì§€"""
        try:
            import cv2
            
            # í”„ë ˆì„ì„ ì„±ëŠ¥ ì„¤ì •ì— ë”°ë¥¸ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ ìµœì í™”)
            target_size = self.performance_config.get("imgsz", 640)
            h, w = frame.shape[:2]
            original_frame_size = (w, h)  # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ìš© ì›ë³¸ í¬ê¸°
            
            if w != target_size or h != target_size:
                frame = cv2.resize(frame, (target_size, target_size), interpolation=cv2.INTER_LINEAR)
            
            # íƒì§€ ìˆ˜í–‰
            annotated, results = self.detector.detect(frame, self.roi)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì„ ìœ„í•œ íƒì§€ ê²°ê³¼ ì²˜ë¦¬
            if results is not None and self.db_manager:
                self._save_detections_to_db(results, original_frame_size)
            
            # ì¹´ìš´íŒ… ë¡œì§ (roiê°€ ìˆì„ ë•Œë§Œ)
            if self.roi and results is not None:
                detections = self._extract_detections(results, self.roi)
                updated_counts = self.tracker.update(detections)
                
                # ì¹´ìš´íŠ¸ ë³€ê²½ ì‹œê·¸ë„ ë°©ì¶œ
                if updated_counts:
                    self.count_changed.emit(dict(updated_counts))
            
            return annotated
            
        except Exception as e:
            print(f"[StreamWorker] í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return frame

    def _extract_detections(self, results, roi) -> list:
        """YOLO ê²°ê³¼ì—ì„œ íƒì§€ëœ ê°ì²´ì˜ ì¤‘ì‹¬ì ê³¼ í´ë˜ìŠ¤ ì¶”ì¶œ"""
        detections = []
        
        try:
            boxes = getattr(results[0], 'boxes', None)
            names = getattr(results[0], 'names', {})
            
            if boxes is not None and hasattr(boxes, 'xyxy'):
                xyxy = boxes.xyxy.tolist() if hasattr(boxes.xyxy, 'tolist') else []
                cls_list = boxes.cls.tolist() if hasattr(boxes, 'cls') and hasattr(boxes.cls, 'tolist') else []
                
                for i, bbox in enumerate(xyxy):
                    if len(bbox) < 4:
                        continue
                        
                    x1, y1, x2, y2 = bbox[:4]
                    cx = x1 + (x2 - x1) / 2.0
                    cy = y1 + (y2 - y1) / 2.0
                    
                    # ROI ì˜¤í”„ì…‹ì„ ê³ ë ¤í•˜ì—¬ ì›ë³¸ í”„ë ˆì„ ì¢Œí‘œë¡œ ë³€í™˜
                    orig_cx = roi[0] + cx
                    orig_cy = roi[1] + cy
                    
                    # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ
                    class_name = 'unknown'
                    if i < len(cls_list):
                        cls_idx = int(cls_list[i])
                        class_name = str(names.get(cls_idx, 'unknown'))
                    
                    detections.append((orig_cx, orig_cy, class_name))
                    
        except Exception as e:
            print(f"[StreamWorker] íƒì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return detections

    def _save_detections_to_db(self, results, original_frame_size):
        """íƒì§€ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            if not self.db_manager or not results:
                return
                
            boxes = getattr(results[0], 'boxes', None)
            names = getattr(results[0], 'names', {})
            
            if boxes is None or not hasattr(boxes, 'xyxy'):
                return
                
            # íƒì§€ ê²°ê³¼ ì¶”ì¶œ
            detections_for_db = []
            xyxy = boxes.xyxy.tolist() if hasattr(boxes.xyxy, 'tolist') else []
            cls_list = boxes.cls.tolist() if hasattr(boxes, 'cls') and hasattr(boxes.cls, 'tolist') else []
            conf_list = boxes.conf.tolist() if hasattr(boxes, 'conf') and hasattr(boxes.conf, 'tolist') else []
            
            frame_width, frame_height = original_frame_size
            
            for i, bbox in enumerate(xyxy):
                if len(bbox) < 4:
                    continue
                    
                x1, y1, x2, y2 = bbox[:4]
                
                # ì •ê·œí™”ëœ ì¢Œí‘œë¡œ ë³€í™˜ (0.0 ~ 1.0)
                norm_x = (x1 + x2) / 2.0 / frame_width
                norm_y = (y1 + y2) / 2.0 / frame_height
                norm_width = (x2 - x1) / frame_width
                norm_height = (y2 - y1) / frame_height
                
                # í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ
                vehicle_class = int(cls_list[i]) if i < len(cls_list) else 0
                vehicle_type = str(names.get(vehicle_class, 'unknown'))
                confidence = float(conf_list[i]) if i < len(conf_list) else 0.0
                
                # ì‹ ë¢°ë„ê°€ ë‚®ì€ íƒì§€ëŠ” ì œì™¸
                if confidence < 0.5:
                    continue
                
                # ì°¨ëŸ‰ íƒ€ì… ë§¤í•‘ (YOLO í´ë˜ìŠ¤ë¥¼ í‘œì¤€ ì°¨ëŸ‰ íƒ€ì…ìœ¼ë¡œ ë³€í™˜)
                vehicle_type_map = {
                    'car': 'car',
                    'motorcycle': 'motorbike',
                    'bus': 'bus',
                    'truck': 'truck',
                    'bicycle': 'motorbike',  # ìì „ê±°ëŠ” ì˜¤í† ë°”ì´ë¡œ ë¶„ë¥˜
                    'van': 'van'
                }
                
                standardized_type = vehicle_type_map.get(vehicle_type.lower(), 'car')
                
                detection_data = {
                    'vehicle_type': standardized_type,
                    'vehicle_class': vehicle_class,
                    'confidence': confidence,
                    'bbox': [norm_x, norm_y, norm_width, norm_height],
                    'frame_number': self.fps_counter,
                    'roi_id': None,  # ROI ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ì„¤ì •
                    'roi_name': None
                }
                
                detections_for_db.append(detection_data)
            
            # íƒì§€ ê²°ê³¼ë¥¼ ë²„í¼ì— ì¶”ê°€
            if detections_for_db:
                self.detection_buffer.extend(detections_for_db)
            
            # ì¼ì • ì‹œê°„ë§ˆë‹¤ ë˜ëŠ” ë²„í¼ê°€ ê°€ë“ ì°° ë•Œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            current_time = time.time()
            buffer_full = len(self.detection_buffer) >= 50  # 50ê°œì”© ë°°ì¹˜ ì €ì¥
            time_to_save = (current_time - self.last_db_save) >= 30  # 30ì´ˆë§ˆë‹¤ ì €ì¥
            
            if (buffer_full or time_to_save) and self.detection_buffer:
                try:
                    success = self.db_manager.record_vehicle_detection(
                        self.camera_id, 
                        self.detection_buffer
                    )
                    
                    if success:
                        saved_count = len(self.detection_buffer)
                        self.detection_buffer.clear()
                        self.last_db_save = current_time
                        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì— {saved_count}ê±´ íƒì§€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
                    else:
                        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
                        
                except Exception as e:
                    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                    
        except Exception as e:
            print(f"[StreamWorker] ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def _frame_to_qimage(self, frame) -> Optional[QtGui.QImage]:
        """OpenCV í”„ë ˆì„ì„ QImageë¡œ ë³€í™˜"""
        try:
            import cv2
            
            # BGR to RGB ë³€í™˜
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb.shape
            bytes_per_line = rgb.strides[0]
            
            qimg = QtGui.QImage(
                rgb.data, w, h, bytes_per_line, QtGui.QImage.Format_RGB888
            )
            
            # QImageê°€ ìì²´ ë²„í¼ë¥¼ ì†Œìœ í•˜ë„ë¡ ë³µì‚¬
            return qimg.copy()
            
        except Exception as e:
            print(f"[StreamWorker] QImage ë³€í™˜ ì˜¤ë¥˜: {e}")
            try:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ í´ë°±
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                h, w = gray.shape
                qimg = QtGui.QImage(gray.data, w, h, w, QtGui.QImage.Format_Grayscale8)
                return qimg.copy()
            except:
                return None

    def reset_count(self):
        """ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
        self.tracker.reset()